{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12661193,"sourceType":"datasetVersion","datasetId":8001395},{"sourceId":12671919,"sourceType":"datasetVersion","datasetId":8007974},{"sourceId":12678828,"sourceType":"datasetVersion","datasetId":8012262},{"sourceId":12719454,"sourceType":"datasetVersion","datasetId":8022866},{"sourceId":514138,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":406490,"modelId":424408}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 0. Установка зависимостей (если ещё не установлено)\n!pip install --quiet ultralytics tqdm pyyaml pillow\n\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\nimport shutil\nimport re\nimport os\nimport numpy as np\nimport random\nimport yaml\nimport pandas as pd\nfrom ultralytics import YOLO\nfrom PIL import Image\nimport cv2\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle\n\n# # === 1. Параметры ===\n# WORK_DIR   = \"/kaggle/working\"\n# LOCAL_BASE = \"/kaggle/input/sliced3\"   # ваш новый датасет\n# NUM_TRAIN  = \n# NUM_VAL    = 5000\n# IMG_SIZE       = 640     # размер картинок для модели\n# BATCH          = 8\n# EPOCHS         = 3\n# CONF_THRES     = 0.25\n# IOU_THRES      = np.arange(0.3, 0.931, 0.07)\n\n\n# # 0. Установка зависимостей (если ещё не установлено)\n# !pip install --quiet ultralytics pyyaml\n\n# import os\n# import yaml\n# from ultralytics import YOLO\n\n\n# === 1. Параметры путей и обучения ===\nWORK_DIR    = '/kaggle/working'\nLIST_DIR    = '/kaggle/input/yolo-8m-80-20'\nTRAIN_LIST    = os.path.join(LIST_DIR, 'train.txt')   # ваш уже существующий train.txt\nVAL_LIST      = os.path.join(LIST_DIR, 'val.txt')     # ваш уже существующий val.txt\nWEIGHTS     = '/kaggle/input/yolo8m-13epochs-train/pytorch/default/1/epoch1.pt'\n\nIMG_SIZE    = 640\nBATCH       = 16\nEPOCHS      = 5\n\nCONF_THRES   = 0.1\nIOU_THRES      = np.arange(0.3, 0.931, 0.07)\n\n# === 2. Data config как dict ===\ndata_cfg = {\n    'path': '/',         # не используется, т.к. train/val — абсолютные пути\n    'train': TRAIN_LIST,\n    'val':   VAL_LIST,\n    'nc':    1,\n    'names': ['person']\n}\ndata_yaml_path = os.path.join(WORK_DIR, 'data.yaml')\nwith open(data_yaml_path, 'w') as f:\n    yaml.dump(data_cfg, f)\n\n# === 3. Гиперпараметры и аугментации ===\nHYP = {\n    # геометрические\n    'degrees':     180,\n    'translate':   0.08,\n    'scale':       0.20,\n    'shear':       0.0,\n    'perspective': 0.0005,\n    'fliplr':      0.5,\n    'flipud':      0.5,\n    # цветовые\n    'hsv_h': 0.015,\n    'hsv_s': 0.40,\n    'hsv_v': 0.30,\n    'bgr':   0.0,\n    # optimizer\n    'lr0':          0.003,\n    'lrf':          0.1,\n    'momentum':     0.937,\n    'weight_decay': 0.0005,\n    # warmup\n    'warmup_epochs':  0.0,\n    'warmup_bias_lr': 0.0,\n    # составные\n    'mosaic': 1.0,\n    'mixup':  0.15,\n}\n\n# === 4. Тренировка ===\nmodel = YOLO(WEIGHTS)\nmodel.train(\n    data=data_yaml_path,    # теперь строка с путём к YAML\n    epochs=EPOCHS,\n    imgsz=IMG_SIZE,\n    batch=BATCH,\n    device=0,\n    augment=True,\n    project=WORK_DIR,\n    name='yolov8s-finetune',\n    conf=CONF_THRES,\n    save=True,         # включаем сохранение чекпоинтов\n    save_period=1,     # сохранять каждый epoch\n    **HYP\n)\n\n\n\n\n# === 3. Функции для оценки ===\ndef get_label_path(img_path):\n    \"\"\"\n    По пути к картинке (img_path) находит правильную папку с разметкой:\n    - sliced1:   .../slices/...  → .../labels/...\n    - sliced2:   .../images1/... → .../labels1/...   (и аналогично images2 → labels2)\n    - sliced3:   .../images/...  → .../labels/...\n    Затем меняет расширение на .txt\n    \"\"\"\n    parts = img_path.split(os.sep)\n    # найдем индекс сегмента, обозначающего \"изображения\"\n    for i, p in enumerate(parts):\n        # варианты названий папок с изображениями:\n        if p.startswith(\"image\") or p == \"slices\":\n            # сформируем соответствующую папку для лейблов\n            if p.startswith(\"images\"):\n                # images, images1, images2 → labels, labels1, labels2\n                label_folder = \"labels\" + p[len(\"images\"):]\n            elif p == \"slices\":\n                # в sliced1 папка называется прямо labels\n                label_folder = \"labels\"\n            else:\n                continue\n\n            # подменяем сегмент и собираем новый путь\n            parts[i] = label_folder\n            label_path = os.sep.join(parts)\n            # меняем расширение на .txt\n            return os.path.splitext(label_path)[0] + \".txt\"\n\n    # если ни один сегмент не подошел — падаем\n    raise ValueError(f\"Не удалось сопоставить путь к разметке для {img_path}\")\n\ndef load_gt(label_path, W, H):\n    boxes = []\n    with open(label_path) as f:\n        for ln in f:\n            parts = ln.split()\n            if len(parts) < 5:\n                continue\n            xc, yc, wb, hb = map(float, parts[1:5])\n            x1 = (xc - wb/2) * W\n            y1 = (yc - hb/2) * H\n            x2 = (xc + wb/2) * W\n            y2 = (yc + hb/2) * H\n            boxes.append([x1, y1, x2, y2])\n    return np.array(boxes)\n\ndef compute_detection_f1(pred_boxes, gt_boxes):\n    \"\"\"\n    pred_boxes, gt_boxes: списки numpy-двумерных массивов [N_i×4] и [M_i×4]\n    Возвращает среднее F1 по порогам IoU от 0.3 до 0.93 с шагом 0.07.\n    \"\"\"\n    thresholds = np.arange(0.3, 0.93+1e-9, 0.07)\n    f1_scores = []\n\n    for t in thresholds:\n        tp = fp = fn = 0\n        for p, g in zip(pred_boxes, gt_boxes):\n            matched_p = set()\n            matched_g = set()\n            if p.size and g.size:\n                inter_wh = np.maximum(\n                    0,\n                    np.minimum(p[:, None, 2:], g[None, :, 2:]) -\n                    np.maximum(p[:, None, :2], g[None, :, :2])\n                )\n                inter_area = inter_wh[...,0] * inter_wh[...,1]\n                area_p = (p[:,2]-p[:,0]) * (p[:,3]-p[:,1])\n                area_g = (g[:,2]-g[:,0]) * (g[:,3]-g[:,1])\n                union = area_p[:,None] + area_g[None,:] - inter_area\n                iou_mat = inter_area / (union + 1e-8)\n\n                idxs = np.argwhere(iou_mat >= t)\n                matches = [(i,j,iou_mat[i,j]) for i,j in idxs]\n                for i,j,score in sorted(matches, key=lambda x: -x[2]):\n                    if i not in matched_p and j not in matched_g:\n                        matched_p.add(i)\n                        matched_g.add(j)\n\n            tp += len(matched_p)\n            fp += p.shape[0] - len(matched_p)\n            fn += g.shape[0] - len(matched_g)\n\n        prec = tp / (tp + fp + 1e-8)\n        rec  = tp / (tp + fn + 1e-8)\n        f1   = 2 * prec * rec / (prec + rec + 1e-8)\n        f1_scores.append(f1)\n\n    return float(np.mean(f1_scores))\n\n\n# === 4. Сбор GT и предиктов ===\n# WEIGHTS_FILE = '/kaggle/input/yolo8m-3epochs-for_inference/pytorch/default/1/best (5).pt'\n# model = YOLO(WEIGHTS_FILE, task='detect')\n\nbest_model_path = os.path.join(WORK_DIR, 'yolov8s-finetune', 'weights', 'best.pt')\nmodel = YOLO(best_model_path, task='detect')\n\nwith open(VAL_LIST) as f:\n    val_imgs = [p.strip() for p in f if p.strip()]\n\npaired_imgs = []\nall_gt = []\nall_pr = []\n\nfor img_path in val_imgs:\n    gt_path = get_label_path(img_path)\n    if not os.path.exists(gt_path):\n        continue  # пропускаем без разметки\n\n    # сохранить синхронный список\n    paired_imgs.append(img_path)\n\n    # загрузка GT\n    W, H = Image.open(img_path).size\n    all_gt.append(load_gt(gt_path, W, H))\n\n    # предсказания\n    res = model.predict(img_path, imgsz=IMG_SIZE, conf=CONF_THRES, verbose=False)[0]\n    all_pr.append(res.boxes.xyxy.cpu().numpy())\n\nprint(f\"Оценка на {len(paired_imgs)} изображениях\")\n\n# === 5. Подсчёт и вывод метрик ===\nmean_f1 = compute_detection_f1(all_pr, all_gt)\nprint(f\"Mean F1 (по IoU 0.3–0.93): {mean_f1:.4f}\")\n\n\n# === 6. Визуализация ===\n# Вариант A: случайно 4 примера\nn = min(len(paired_imgs), 4)\nsample_idxs = random.sample(range(len(paired_imgs)), k=n)\n\n# Вариант B (если хотите все подряд):\n# sample_idxs = list(range(len(paired_imgs)))\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 12))\nfor ax, idx in zip(axes.flatten(), sample_idxs):\n    img_path = paired_imgs[idx]\n    im = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n    ax.imshow(im)\n    ax.axis('off')\n\n    # рисуем GT\n    for x1,y1,x2,y2 in all_gt[idx]:\n        ax.add_patch(Rectangle((x1,y1),\n                               x2-x1, y2-y1,\n                               edgecolor='lime', lw=2, fill=False))\n    # рисуем предсказания\n    for x1,y1,x2,y2 in all_pr[idx]:\n        ax.add_patch(Rectangle((x1,y1),\n                               x2-x1, y2-y1,\n                               edgecolor='red', lw=2, fill=False))\n\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-06T21:57:15.554120Z","iopub.execute_input":"2025-08-06T21:57:15.554399Z","iopub.status.idle":"2025-08-06T22:33:34.941140Z","shell.execute_reply.started":"2025-08-06T21:57:15.554378Z","shell.execute_reply":"2025-08-06T22:33:34.940061Z"}},"outputs":[],"execution_count":null}]}